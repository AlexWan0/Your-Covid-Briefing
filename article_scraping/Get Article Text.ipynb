{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from goose3 import Goose\n",
    "g = Goose({'enable_image_fetching':False, 'browser_user_agent': 'Mozilla'})\n",
    "def extract_text(article_url):\n",
    "    article = g.extract(url=article_url)\n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import unquote\n",
    "\n",
    "prefix_blacklist = ['https://www.google.com', 'https://www.google.com/search?q=', 'https://support.google.com', 'https://www.google.com/intl/en/about/products', 'https://accounts.google.com', 'https://maps.google.com/maps', 'https://www.google.com/flights', 'https://www.google.com/preferences', 'https://www.google.com/setprefs', 'https://www.google.com/history', 'https://www.google.com/alerts', 'https://newsinitiative.withgoogle.com', 'https://policies.google.com', 'https://newsinitiative.withgoogle.com']\n",
    "\n",
    "def check_prefixes(link, blacklist=prefix_blacklist):\n",
    "    for p in blacklist:\n",
    "        if link[:len(p)] == p:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def convert_gamp(link, prefix='https://www.google.com/url'):\n",
    "    if link[:len(prefix)] == prefix:\n",
    "        return unquote(link.split('&url=')[1])\n",
    "    return link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = set()\n",
    "for csv_path in glob('scraped/*/FINAL.csv'):\n",
    "    new_urls = pd.read_csv(csv_path)['url'].to_list()\n",
    "    urls.update(new_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_urls = list(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = list(map(convert_gamp, raw_urls))\n",
    "urls = list(filter(check_prefixes, urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4559"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebcc482e57fe436bb28ccda1c1e4c206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4559.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alex\\anaconda3\\envs\\scrape_news\\lib\\site-packages\\dateutil\\parser\\_parser.py:1218: UnknownTimezoneWarning: tzname EDT identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  category=UnknownTimezoneWarning)\n",
      "c:\\users\\alex\\anaconda3\\envs\\scrape_news\\lib\\site-packages\\dateutil\\parser\\_parser.py:1218: UnknownTimezoneWarning: tzname PT identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  category=UnknownTimezoneWarning)\n",
      "c:\\users\\alex\\anaconda3\\envs\\scrape_news\\lib\\site-packages\\dateutil\\parser\\_parser.py:1218: UnknownTimezoneWarning: tzname IST identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  category=UnknownTimezoneWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alex\\anaconda3\\envs\\scrape_news\\lib\\site-packages\\dateutil\\parser\\_parser.py:1218: UnknownTimezoneWarning: tzname EST identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  category=UnknownTimezoneWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alex\\anaconda3\\envs\\scrape_news\\lib\\site-packages\\dateutil\\parser\\_parser.py:1218: UnknownTimezoneWarning: tzname PDT identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  category=UnknownTimezoneWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alex\\anaconda3\\envs\\scrape_news\\lib\\site-packages\\dateutil\\parser\\_parser.py:1218: UnknownTimezoneWarning: tzname PST identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  category=UnknownTimezoneWarning)\n",
      "c:\\users\\alex\\anaconda3\\envs\\scrape_news\\lib\\site-packages\\dateutil\\parser\\_parser.py:1218: UnknownTimezoneWarning: tzname ET identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  category=UnknownTimezoneWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Unicode strings with encoding declaration are not supported. Please use bytes input or XML fragments without declaration.\n",
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "HTTPSConnectionPool(host='charlottenc.gov', port=443): Max retries exceeded with url: /covid19/Pages/default.aspx (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1076)')))\n",
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "HTTPSConnectionPool(host='www.hindustantimes.com', port=443): Read timed out. (read timeout=30.0)\n",
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "skipped 35\n",
      "saving...\n"
     ]
    }
   ],
   "source": [
    "num_skipped = 0\n",
    "text_objects = []\n",
    "\n",
    "for u in tqdm(urls):\n",
    "    try:\n",
    "        article_goose = extract_text(u)\n",
    "        text_objects.append(article_goose.infos)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        num_skipped += 1\n",
    "\n",
    "print('skipped %d' % num_skipped)\n",
    "\n",
    "print('saving...')\n",
    "with open('article_objects.pkl', 'wb') as file_out:\n",
    "    pickle.dump(text_objects, file_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4467"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_empty = []\n",
    "for to in text_objects:\n",
    "    if not to['cleaned_text'] == '':\n",
    "        no_empty.append(to)\n",
    "text_objects = no_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...\n"
     ]
    }
   ],
   "source": [
    "print('saving...')\n",
    "with open('article_objects_noempty.pkl', 'wb') as file_out:\n",
    "    pickle.dump(text_objects, file_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading...\n"
     ]
    }
   ],
   "source": [
    "print('loading...')\n",
    "with open('article_objects_noempty.pkl', 'rb') as file_in:\n",
    "    text_objects = pickle.load(file_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(text_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = df['cleaned_text'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Alex\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Alex\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2f716ee234b471eae8f08af73555d3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1607), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "lemmatiser = WordNetLemmatizer()\n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "\n",
    "def preprocess(raw):\n",
    "    result = unidecode(raw)\n",
    "    result = re.sub(r'(https?:\\/\\/)?([a-zA-Z0-9-_]{1,}\\.){1,}[a-zA-Z0-9-_]{1,}(\\/[A-Za-z0-9-._~:?#\\[\\]@!$&\\'()*+,;%=]{1,}){0,}\\/?', '', result)\n",
    "    result = re.sub(r\"[^a-zA-Z]\", \" \", result)\n",
    "    result = re.sub(' +', ' ', result)\n",
    "    result = result.lower()\n",
    "    result = stemmer.stem(result)\n",
    "    result = [lemmatiser.lemmatize(w) for w in result.split(' ')]\n",
    "    result = [w for w in result if w not in cachedStopWords]\n",
    "    return result\n",
    "\n",
    "tp = []\n",
    "for article in tqdm(text_data):\n",
    "    tp.append(preprocess(article))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed_text.pkl', 'wb') as file_out:\n",
    "    pickle.dump(tp, file_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
